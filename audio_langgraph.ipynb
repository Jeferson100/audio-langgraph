{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93a593f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!uv pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f109326b-af8d-43bd-8a61-2572106858bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langchain_groq import ChatGroq\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated, List\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    SystemMessage\n",
    ")\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "chat = ChatGroq(\n",
    "    model=\"meta-llama/llama-4-maverick-17b-128e-instruct\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    \n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=\"\"\"You are a helpful assistant that can answer any question. \n",
    "                      You can also say 'I don't know' if you don't know the answer.\n",
    "                      Your answer should be in Portuguese.\"\"\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def chat_groq(state):\n",
    "    message = state['messages'][-1]\n",
    "    response = chat.invoke(prompt_template.format(input=message))\n",
    "    return {\"messages\": response.content}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9f1010f-7d57-41fd-9993-bfa11119e8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.invoke(\"Tudo bem com vc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a06c91e-30b3-499b-9654-c6ca47864a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Estou bem, obrigado por perguntar! Sou um modelo de linguagem treinado por máquina, então não tenho sentimentos ou emoções como os humanos, mas estou funcionando corretamente e pronto para ajudar com qualquer coisa que você precise. Como posso ajudar você hoje?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fae5ca50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': 'Tudo bem, obrigado por perguntar! Estou aqui para ajudar com qualquer coisa que você precise. Como posso ajudar você hoje?'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat_groq({\"messages\": [\"Tudo bem com vc\"]})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebe1b34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(State)\n",
    "\n",
    "graph.add_node(\"chat_groq\", chat_groq)\n",
    "graph.add_edge(START, \"chat_groq\")\n",
    "graph.add_edge(\"chat_groq\", END)\n",
    "\n",
    "graph_compiled = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d8a7d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='que dia e hoje', additional_kwargs={}, response_metadata={}, id='fea6ce29-6d74-41ce-821d-8458b9c02c85'),\n",
       "  HumanMessage(content='Hoje é sexta-feira, 19 de abril de 2024 (a data pode variar de acordo com a data atual). Para saber a data exata, você pode verificar o seu calendário ou dispositivo.', additional_kwargs={}, response_metadata={}, id='b383e9ab-8ffe-420c-8b3e-addc42abc7ab')]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_compiled.invoke({\"messages\": \"que dia e hoje\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8212710",
   "metadata": {},
   "source": [
    "### Connect to your deployment\n",
    "\n",
    "Connect to your deployment using the URL endpoint:\n",
    "- **Studio**: Found in Studio UI \n",
    "- **CLI**: Printed to console (typically `http://localhost:2024`)\n",
    "- **Cloud**: Available in LangGraph Deployment page\n",
    "\n",
    "We'll connect to the deployment as a [RemoteGraph](https://langchain-ai.github.io/langgraph/how-tos/use-remote-graph/#how-to-interact-with-the-deployment-using-remotegraph). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b42b4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.pregel.remote import RemoteGraph\n",
    "from langchain_core.messages import convert_to_messages\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Local deployment (via LangGraph Studio)\n",
    "local_deployment_url = \"http://localhost:2024\"\n",
    "\n",
    "# Deployment URL\n",
    "#cloud_deployment_url = \"https://task-maistro-1b681add7a2b549499bb0cd21a7e5be4.default.us.langgraph.app\"\n",
    "\n",
    "# Graph name\n",
    "graph_name = \"audio-langgraph\" \n",
    "\n",
    "# Connect to the deployment\n",
    "remote_graph = RemoteGraph(graph_name, url=local_deployment_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed85d33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': \"Hi I'm Lance. I live in San Francisco with my wife and have a 1 year old.\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': 'cb6b35bf-ffa5-4be3-b8c7-59cc2f4a9045', 'example': False}]\n",
      "[{'content': \"Hi I'm Lance. I live in San Francisco with my wife and have a 1 year old.\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': 'cb6b35bf-ffa5-4be3-b8c7-59cc2f4a9045', 'example': False}, {'content': 'Olá Lance! É um prazer conhecê-lo. Você parece ter uma vida muito interessante em San Francisco com sua esposa e seu filho de 1 ano. Como posso ajudá-lo hoje? Você tem alguma pergunta ou precisa de alguma informação específica? Estou aqui para ajudar!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': 'dca7c71e-038a-4553-9fa9-7cc43f81dd53', 'example': False}]\n"
     ]
    }
   ],
   "source": [
    "# Int\n",
    "user_input = \"Hi I'm Lance. I live in San Francisco with my wife and have a 1 year old.\"\n",
    "config = {\"configurable\": {\"user_id\": \"Test-Deployment-User\"}}\n",
    "for chunk in remote_graph.stream({\"messages\": user_input}, stream_mode=\"values\", config=config):\n",
    "    print(chunk[\"messages\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1092a7ef",
   "metadata": {},
   "source": [
    "### Add audio\n",
    "\n",
    "Our deployed graph has some benefits: \n",
    "* It has built-in support for long-term memory \n",
    "* It implements all the logic for task mAIstro \n",
    "\n",
    "But, we have a challenge:\n",
    "* It takes test as input and returns text as output\n",
    "\n",
    "We need to add audio input and output to the graph. So, we'll simply add two nodes to our graph:\n",
    "\n",
    "1. **Audio Input Node**\n",
    "   * Records microphone input (stop with Enter)\n",
    "   * Transcribes speech using Whisper\n",
    "   * Passes text to Task mAIstro\n",
    "\n",
    "2. **Audio Output Node**\n",
    "   * Takes Task mAIstro's text response\n",
    "   * Converts to speech via ElevenLabs\n",
    "   * Plays audio response\n",
    "\n",
    "We can achieve this by embedding our deployed graph [as a node](https://langchain-ai.github.io/langgraph/how-tos/use-remote-graph/#using-as-a-subgraph) in a new graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "add8f0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.4)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import threading\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "from IPython.display import Image, display\n",
    "import pygame\n",
    "import tempfile\n",
    "import os\n",
    "from groq import Groq\n",
    "from langgraph.graph import StateGraph, MessagesState, END, START\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Groq client\n",
    "groq_client = Groq()\n",
    "\n",
    "def record_audio_until_stop(state: State):\n",
    "    \"\"\"Records audio from the microphone until Enter is pressed, then saves it to a .wav file.\"\"\"\n",
    "    \n",
    "    audio_data = []  # List to store audio chunks\n",
    "    recording = True  # Flag to control recording\n",
    "    sample_rate = 16000  # (kHz) Adequate for human voice frequency\n",
    "    \n",
    "    def record_audio():\n",
    "        \"\"\"Continuously records audio until the recording flag is set to False.\"\"\"\n",
    "        nonlocal audio_data, recording\n",
    "        with sd.InputStream(samplerate=sample_rate, channels=1, dtype='int16') as stream:\n",
    "            print(\"Recording your instruction! ... Press Enter to stop recording.\")\n",
    "            while recording:\n",
    "                audio_chunk, _ = stream.read(1024)  # Read audio data in chunks\n",
    "                audio_data.append(audio_chunk)\n",
    "\n",
    "    def stop_recording():\n",
    "        \"\"\"Waits for user input to stop the recording.\"\"\"\n",
    "        input()  # Wait for Enter key press\n",
    "        nonlocal recording\n",
    "        recording = False\n",
    "\n",
    "    # Start recording in a separate thread\n",
    "    recording_thread = threading.Thread(target=record_audio)\n",
    "    recording_thread.start()\n",
    "\n",
    "    # Start a thread to listen for the Enter key\n",
    "    stop_thread = threading.Thread(target=stop_recording)\n",
    "    stop_thread.start()\n",
    "\n",
    "    # Wait for both threads to complete\n",
    "    stop_thread.join()\n",
    "    recording_thread.join()\n",
    "\n",
    "    # Stack all audio chunks into a single NumPy array and write to file\n",
    "    audio_data = np.concatenate(audio_data, axis=0)\n",
    "    \n",
    "    # Create a temporary WAV file for Groq API\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_file:\n",
    "        write(temp_file.name, sample_rate, audio_data)\n",
    "        temp_filename = temp_file.name\n",
    "    \n",
    "    try:\n",
    "        # Transcribe via Groq Whisper\n",
    "        with open(temp_filename, \"rb\") as file:\n",
    "            transcription = groq_client.audio.transcriptions.create(\n",
    "                file=(temp_filename, file.read()),\n",
    "                model=\"whisper-large-v3\",\n",
    "                prompt=\"Transcreva o áudio em português brasileiro\",\n",
    "                response_format=\"json\",\n",
    "                temperature=0.0\n",
    "            )\n",
    "    finally:\n",
    "        # Clean up temporary file\n",
    "        os.unlink(temp_filename)\n",
    "    \n",
    "    # Print the transcription\n",
    "    print(\"Here is the transcription:\", transcription.text)\n",
    "    \n",
    "    # Write to messages \n",
    "    return {\"messages\": [HumanMessage(content=transcription.text)]}\n",
    "\n",
    "def play_audio(state: State):\n",
    "    \"\"\"Plays the audio response using Groq TTS.\"\"\"\n",
    "    \n",
    "    # Response from the agent \n",
    "    response = state['messages'][-1]\n",
    "    \n",
    "    # Prepare text by replacing ** with empty strings\n",
    "    # These can cause unexpected behavior in TTS\n",
    "    if isinstance(response, str):\n",
    "        cleaned_text = response.replace(\"**\", \"\")\n",
    "    else:\n",
    "        cleaned_text = response.content.replace(\"**\", \"\")\n",
    "    \n",
    "    try:\n",
    "        # Call Groq text-to-speech API\n",
    "        tts_response = groq_client.audio.speech.create(\n",
    "            model=\"playai-tts\",\n",
    "            voice=\"Atlas-PlayAI\",  # You can change this to other available voices\n",
    "            input=cleaned_text,\n",
    "            response_format=\"wav\"\n",
    "        )\n",
    "    \n",
    "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_file:\n",
    "            tts_response.write_to_file(temp_file.name)\n",
    "            temp_audio_file = temp_file.name\n",
    "        \n",
    "        # Play the audio using pygame\n",
    "        pygame.mixer.init()\n",
    "        pygame.mixer.music.load(temp_audio_file)\n",
    "        pygame.mixer.music.play()\n",
    "        \n",
    "        # Wait for the audio to finish playing\n",
    "        while pygame.mixer.music.get_busy():\n",
    "            pygame.time.wait(100)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in text-to-speech: {e}\")\n",
    "    finally:\n",
    "        # Clean up temporary file\n",
    "        if 'temp_audio_file' in locals():\n",
    "            try:\n",
    "                os.unlink(temp_audio_file)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "# Alternative play_audio function using sounddevice (if pygame doesn't work)\n",
    "def play_audio_alternative(state: State):\n",
    "    \"\"\"Alternative audio playback using sounddevice.\"\"\"\n",
    "    \n",
    "    response = state['messages'][-1]\n",
    "    if isinstance(response, str):\n",
    "        cleaned_text = response.replace(\"**\", \"\")\n",
    "    else:\n",
    "        cleaned_text = response.content.replace(\"**\", \"\")\n",
    "    try:\n",
    "        # Call Groq text-to-speech API\n",
    "        tts_response = groq_client.audio.speech.create(\n",
    "            model=\"playai-tts\",\n",
    "            voice=\"Arista-PlayAI\",\n",
    "            input=cleaned_text,\n",
    "            response_format=\"wav\"\n",
    "        )\n",
    "        \n",
    "        # Create temporary file and read audio data\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_file:\n",
    "            tts_response.write_to_file(temp_file.name)\n",
    "            temp_audio_file = temp_file.name\n",
    "        \n",
    "        # Read the WAV file and play with sounddevice\n",
    "        from scipy.io.wavfile import read\n",
    "        sample_rate, audio_data = read(temp_audio_file)\n",
    "        sd.play(audio_data, sample_rate)\n",
    "        sd.wait()  # Wait until the audio finishes playing\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in text-to-speech: {e}\")\n",
    "    finally:\n",
    "        # Clean up\n",
    "        if 'temp_audio_file' in locals():\n",
    "            try:\n",
    "                os.unlink(temp_audio_file)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "# choco install ffmpeg\n",
    "# site para vozes https://elevenlabs.io/app/voice-library?search=brazil\n",
    "from dotenv import load_dotenv\n",
    "from elevenlabs.client import ElevenLabs\n",
    "from elevenlabs import play\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "elevenlabs = ElevenLabs(\n",
    "  api_key=os.getenv(\"ELEVENLABS_API_KEY\"),\n",
    ")\n",
    "\n",
    "def play_audio(state: State):\n",
    "    \"\"\"Plays the audio response using Groq TTS.\"\"\"\n",
    "    \n",
    "    # Response from the agent \n",
    "    response = state['messages'][-1]\n",
    "    \n",
    "    # Prepare text by replacing ** with empty strings\n",
    "    # These can cause unexpected behavior in TTS\n",
    "    if isinstance(response, str):\n",
    "        cleaned_text = response.replace(\"**\", \"\")\n",
    "    else:\n",
    "        cleaned_text = response.content.replace(\"**\", \"\")\n",
    "\n",
    "    try:\n",
    "        audio = elevenlabs.text_to_speech.convert(\n",
    "            text=cleaned_text,\n",
    "            #voice_id=\"JBFqnCBsd6RMkjVDRZzb\",\n",
    "            #model_id=\"eleven_multilingual_v2\",\n",
    "            #voice_id=\"GnDrTQvdzZ7wqAKfLzVQ\",\n",
    "            #voice_id = \"8ydzsJeYlXGq5mRMX93B\",\n",
    "            voice_id=\"EIkHVdkuarjkYUyMnoes\",\n",
    "            \n",
    "            model_id=\"eleven_multilingual_v1\",\n",
    "            output_format=\"mp3_44100_128\",\n",
    "        )\n",
    "\n",
    "        play(audio)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in elevenlabs: {e}\")\n",
    "        try:\n",
    "            # Call Groq text-to-speech API\n",
    "            tts_response = groq_client.audio.speech.create(\n",
    "                model=\"playai-tts\",\n",
    "                voice=\"Arista-PlayAI\",\n",
    "                input=cleaned_text,\n",
    "                response_format=\"wav\"\n",
    "            )\n",
    "            \n",
    "            # Create temporary file and read audio data\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_file:\n",
    "                tts_response.write_to_file(temp_file.name)\n",
    "                temp_audio_file = temp_file.name\n",
    "            \n",
    "            # Read the WAV file and play with sounddevice\n",
    "            from scipy.io.wavfile import read\n",
    "            sample_rate, audio_data = read(temp_audio_file)\n",
    "            sd.play(audio_data, sample_rate)\n",
    "            sd.wait()  # Wait until the audio finishes playing\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in text-to-speech: {e}\")\n",
    "        finally:\n",
    "            # Clean up\n",
    "            if 'temp_audio_file' in locals():\n",
    "                try:\n",
    "                    os.unlink(temp_audio_file)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langchain_groq import ChatGroq\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List, Annotated\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "load_dotenv()\n",
    "\n",
    "chat = ChatGroq(\n",
    "    model=\"meta-llama/llama-4-maverick-17b-128e-instruct\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    \n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=\"\"\"You are a helpful assistant that can answer any question. \n",
    "                      You can also say 'I don't know' if you don't know the answer.\n",
    "                      Your answer should be in Portuguese.\"\"\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def chat_groq(state):\n",
    "    message = state['messages'][-1]\n",
    "    response = chat.invoke(prompt_template.format(input=message))\n",
    "    return {\"messages\": response.content}\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = StateGraph(State)\n",
    "graph.add_node(\"audio_input\", record_audio_until_stop)\n",
    "graph.add_node(\"chat_groq\", chat_groq)\n",
    "graph.add_node(\"audio_output\", play_audio)\n",
    "\n",
    "graph.add_edge(START, \"audio_input\")\n",
    "graph.add_edge(\"audio_input\", \"chat_groq\")\n",
    "graph.add_edge(\"chat_groq\", \"audio_output\")\n",
    "graph.add_edge(\"audio_output\", END)\n",
    "\n",
    "graph_compiled = graph.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "942ddedf-8d6a-43a4-af89-43ef6adda62f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## docker run -p 3000:3000 ghcr.io/jihchi/mermaid.ink \n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph_compiled.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ad3a44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "thread_id = str(uuid.uuid4())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29eb1542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content=\"Follow the user's instructions:\", additional_kwargs={}, response_metadata={}, id='a34d14c1-6f02-445e-92af-e9480be4d694')]\n",
      "Recording your instruction! ... Press Enter to stop recording.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the transcription:  Olá, tudo bem?\n",
      "[HumanMessage(content=\"Follow the user's instructions:\", additional_kwargs={}, response_metadata={}, id='a34d14c1-6f02-445e-92af-e9480be4d694'), HumanMessage(content=' Olá, tudo bem?', additional_kwargs={}, response_metadata={}, id='b092714e-e223-4471-9ea8-6c268d0f71f8')]\n",
      "[HumanMessage(content=\"Follow the user's instructions:\", additional_kwargs={}, response_metadata={}, id='a34d14c1-6f02-445e-92af-e9480be4d694'), HumanMessage(content=' Olá, tudo bem?', additional_kwargs={}, response_metadata={}, id='b092714e-e223-4471-9ea8-6c268d0f71f8'), HumanMessage(content='Olá! Sim, tudo bem! Como posso ajudar você hoje?', additional_kwargs={}, response_metadata={}, id='63cfd078-fca1-4afd-9bf0-67e60eb86285')]\n",
      "Error in elevenlabs: headers: {'date': 'Fri, 15 Aug 2025 12:51:26 GMT', 'server': 'uvicorn', 'content-length': '171', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'access-control-allow-headers': '*', 'access-control-allow-methods': 'POST, PATCH, OPTIONS, DELETE, GET, PUT', 'access-control-max-age': '600', 'strict-transport-security': 'max-age=31536000; includeSubDomains', 'x-trace-id': '7ea9fa7ea53953758ed0203358083227', 'x-region': 'us-central1', 'via': '1.1 google, 1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 401, body: {'detail': {'status': 'quota_exceeded', 'message': 'This request exceeds your quota of 10000. You have 12 credits remaining, while 48 credits are required for this request.'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jefer\\AppData\\Local\\Temp\\ipykernel_39764\\4060166178.py:225: WavFileWarning: Reached EOF prematurely; finished at 537681 bytes, expected 4294967303 bytes from header.\n",
      "  sample_rate, audio_data = read(temp_audio_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the transcription:  Olá, tudo bem? Como você está? Olá, tudo bem? Como você está?\n",
      "[HumanMessage(content=\"Follow the user's instructions:\", additional_kwargs={}, response_metadata={}, id='d2b05ce4-226b-4c9a-8b78-03c9ad3c7725'), HumanMessage(content=' Olá, tudo bem? Como você está? Olá, tudo bem? Como você está?', additional_kwargs={}, response_metadata={}, id='4d3633f9-7142-4508-9383-0bd36452c5a4')]\n",
      "[HumanMessage(content=\"Follow the user's instructions:\", additional_kwargs={}, response_metadata={}, id='d2b05ce4-226b-4c9a-8b78-03c9ad3c7725'), HumanMessage(content=' Olá, tudo bem? Como você está? Olá, tudo bem? Como você está?', additional_kwargs={}, response_metadata={}, id='4d3633f9-7142-4508-9383-0bd36452c5a4'), HumanMessage(content='Olá! Estou bem, obrigado por perguntar! Parece que você repetiu a pergunta, mas não há problema. Estou aqui para ajudar e responder às suas perguntas da melhor forma possível. Como posso ajudar você hoje?', additional_kwargs={}, response_metadata={}, id='c3f96ea2-34d1-4450-a517-1f7e4887c653')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the transcription:  Olá, tudo bem?\n",
      "[HumanMessage(content=\"Follow the user's instructions:\", additional_kwargs={}, response_metadata={}, id='9896d36a-30fb-4b47-af76-34fcf9685aba'), HumanMessage(content=' Olá, tudo bem?', additional_kwargs={}, response_metadata={}, id='d1e1ccbd-d706-46d3-b394-021a55f0e426')]\n",
      "[HumanMessage(content=\"Follow the user's instructions:\", additional_kwargs={}, response_metadata={}, id='9896d36a-30fb-4b47-af76-34fcf9685aba'), HumanMessage(content=' Olá, tudo bem?', additional_kwargs={}, response_metadata={}, id='d1e1ccbd-d706-46d3-b394-021a55f0e426'), HumanMessage(content='Olá! Sim, tudo bem! Como posso ajudar você hoje?', additional_kwargs={}, response_metadata={}, id='e33ddf6c-02ea-44ca-81ea-3add4fb0101a')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the transcription:  Olá, tudo bem com você?\n",
      "[HumanMessage(content=' Olá, tudo bem com você?', additional_kwargs={}, response_metadata={})]\n",
      "Olá! Sim, estou funcionando corretamente, obrigado por perguntar! Estou aqui para ajudar com qualquer coisa que você precise. Como posso ajudar você hoje?\n",
      "Error in text-to-speech: Error code: 500 - {'error': {'message': 'Internal Server Error', 'type': 'internal_server_error'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the transcription:  Olá, tudo bem? Meu nome é Jefferson.\n",
      "[HumanMessage(content=' Olá, tudo bem? Meu nome é Jefferson.', additional_kwargs={}, response_metadata={})]\n",
      "Olá Jefferson! Tudo bem, sim! É um prazer conhecê-lo! Como posso ajudar você hoje?\n",
      "Error in text-to-speech: Error code: 500 - {'error': {'message': 'Internal Server Error', 'type': 'internal_server_error'}}\n"
     ]
    }
   ],
   "source": [
    "# Set user ID for storing memories\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "initial_state = {\"messages\": [\"Olá, como você está?\"]}\n",
    "for chunk in graph_compiled.stream({\"messages\":HumanMessage(content=\"Follow the user's instructions:\")}, stream_mode=\"values\", config=config):\n",
    "    print(chunk[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3c0304c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content=\"Follow the user's instructions:\", additional_kwargs={}, response_metadata={}, id='a34d14c1-6f02-445e-92af-e9480be4d694'), HumanMessage(content=' Olá, tudo bem?', additional_kwargs={}, response_metadata={}, id='b092714e-e223-4471-9ea8-6c268d0f71f8'), HumanMessage(content='Olá! Sim, tudo bem! Como posso ajudar você hoje?', additional_kwargs={}, response_metadata={}, id='63cfd078-fca1-4afd-9bf0-67e60eb86285'), HumanMessage(content=\"Follow the user's instructions:\", additional_kwargs={}, response_metadata={}, id='d14de755-641f-4ccb-be87-9190efe527f1')]\n",
      "Recording your instruction! ... Press Enter to stop recording.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the transcription:  Olá, tudo bem?\n",
      "[HumanMessage(content=\"Follow the user's instructions:\", additional_kwargs={}, response_metadata={}, id='a34d14c1-6f02-445e-92af-e9480be4d694'), HumanMessage(content=' Olá, tudo bem?', additional_kwargs={}, response_metadata={}, id='b092714e-e223-4471-9ea8-6c268d0f71f8'), HumanMessage(content='Olá! Sim, tudo bem! Como posso ajudar você hoje?', additional_kwargs={}, response_metadata={}, id='63cfd078-fca1-4afd-9bf0-67e60eb86285'), HumanMessage(content=\"Follow the user's instructions:\", additional_kwargs={}, response_metadata={}, id='d14de755-641f-4ccb-be87-9190efe527f1'), HumanMessage(content=' Olá, tudo bem?', additional_kwargs={}, response_metadata={}, id='3019e04f-decd-46dd-95e0-2cf2be1a1277')]\n",
      "[HumanMessage(content=\"Follow the user's instructions:\", additional_kwargs={}, response_metadata={}, id='a34d14c1-6f02-445e-92af-e9480be4d694'), HumanMessage(content=' Olá, tudo bem?', additional_kwargs={}, response_metadata={}, id='b092714e-e223-4471-9ea8-6c268d0f71f8'), HumanMessage(content='Olá! Sim, tudo bem! Como posso ajudar você hoje?', additional_kwargs={}, response_metadata={}, id='63cfd078-fca1-4afd-9bf0-67e60eb86285'), HumanMessage(content=\"Follow the user's instructions:\", additional_kwargs={}, response_metadata={}, id='d14de755-641f-4ccb-be87-9190efe527f1'), HumanMessage(content=' Olá, tudo bem?', additional_kwargs={}, response_metadata={}, id='3019e04f-decd-46dd-95e0-2cf2be1a1277'), HumanMessage(content='Olá! Sim, tudo bem! Como posso ajudar você hoje?', additional_kwargs={}, response_metadata={}, id='4941e2dd-8335-4935-9211-8193897c72aa')]\n",
      "Error in elevenlabs: headers: {'date': 'Fri, 15 Aug 2025 12:51:40 GMT', 'server': 'uvicorn', 'content-length': '171', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'access-control-allow-headers': '*', 'access-control-allow-methods': 'POST, PATCH, OPTIONS, DELETE, GET, PUT', 'access-control-max-age': '600', 'strict-transport-security': 'max-age=31536000; includeSubDomains', 'x-trace-id': 'ebe320aea113293879d9f1fbd337c52c', 'x-region': 'us-central1', 'via': '1.1 google, 1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 401, body: {'detail': {'status': 'quota_exceeded', 'message': 'This request exceeds your quota of 10000. You have 12 credits remaining, while 48 credits are required for this request.'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jefer\\AppData\\Local\\Temp\\ipykernel_39764\\4060166178.py:225: WavFileWarning: Reached EOF prematurely; finished at 537681 bytes, expected 4294967303 bytes from header.\n",
      "  sample_rate, audio_data = read(temp_audio_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the transcription:  Você sabe que dia é hoje? O que poderia me dizer isso?\n",
      "[HumanMessage(content=\"Follow the user's instructions:\", additional_kwargs={}, response_metadata={}, id='d2b05ce4-226b-4c9a-8b78-03c9ad3c7725'), HumanMessage(content=' Olá, tudo bem? Como você está? Olá, tudo bem? Como você está?', additional_kwargs={}, response_metadata={}, id='4d3633f9-7142-4508-9383-0bd36452c5a4'), HumanMessage(content='Olá! Estou bem, obrigado por perguntar! Parece que você repetiu a pergunta, mas não há problema. Estou aqui para ajudar e responder às suas perguntas da melhor forma possível. Como posso ajudar você hoje?', additional_kwargs={}, response_metadata={}, id='c3f96ea2-34d1-4450-a517-1f7e4887c653'), HumanMessage(content=\"Follow the user's instructions:\", additional_kwargs={}, response_metadata={}, id='7cb88d3a-54f2-44c0-beb4-4bb5c5d4ebdb'), HumanMessage(content=' Você sabe que dia é hoje? O que poderia me dizer isso?', additional_kwargs={}, response_metadata={}, id='6604e9db-4dfb-4b43-9657-9c647d9f225b')]\n",
      "[HumanMessage(content=\"Follow the user's instructions:\", additional_kwargs={}, response_metadata={}, id='d2b05ce4-226b-4c9a-8b78-03c9ad3c7725'), HumanMessage(content=' Olá, tudo bem? Como você está? Olá, tudo bem? Como você está?', additional_kwargs={}, response_metadata={}, id='4d3633f9-7142-4508-9383-0bd36452c5a4'), HumanMessage(content='Olá! Estou bem, obrigado por perguntar! Parece que você repetiu a pergunta, mas não há problema. Estou aqui para ajudar e responder às suas perguntas da melhor forma possível. Como posso ajudar você hoje?', additional_kwargs={}, response_metadata={}, id='c3f96ea2-34d1-4450-a517-1f7e4887c653'), HumanMessage(content=\"Follow the user's instructions:\", additional_kwargs={}, response_metadata={}, id='7cb88d3a-54f2-44c0-beb4-4bb5c5d4ebdb'), HumanMessage(content=' Você sabe que dia é hoje? O que poderia me dizer isso?', additional_kwargs={}, response_metadata={}, id='6604e9db-4dfb-4b43-9657-9c647d9f225b'), HumanMessage(content='Sim, posso te ajudar com isso. No entanto, não tenho acesso à data e hora atual. Mas posso sugerir algumas opções para você descobrir que dia é hoje.\\n\\nVocê pode verificar o calendário na sua parede ou no seu dispositivo móvel, como um smartphone ou um relógio digital. Além disso, muitos sistemas operacionais de computadores e dispositivos móveis também exibem a data atual.\\n\\nSe você estiver usando um dispositivo com acesso à internet, também pode procurar por \"que dia é hoje\" em um mecanismo de busca para obter a resposta.\\n\\nSe eu soubesse a data atual, eu poderia te dizer o dia da semana correspondente. Por exemplo, se hoje fosse uma segunda-feira, eu diria \"Hoje é segunda-feira\". Mas, como não tenho essa informação, sugiro que você verifique em um dos lugares que mencionei.\\n\\nPosso ajudar com mais alguma coisa?', additional_kwargs={}, response_metadata={}, id='c422b29f-e6e0-47ae-a92b-f343d8e32ab5')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the transcription:  me fale sobre o clube de futebol do Brasil Palmeiras\n",
      "[HumanMessage(content=\"Follow the user's instructions:\", additional_kwargs={}, response_metadata={}, id='9896d36a-30fb-4b47-af76-34fcf9685aba'), HumanMessage(content=' Olá, tudo bem?', additional_kwargs={}, response_metadata={}, id='d1e1ccbd-d706-46d3-b394-021a55f0e426'), HumanMessage(content='Olá! Sim, tudo bem! Como posso ajudar você hoje?', additional_kwargs={}, response_metadata={}, id='e33ddf6c-02ea-44ca-81ea-3add4fb0101a'), HumanMessage(content=\"Follow the user's instructions:\", additional_kwargs={}, response_metadata={}, id='01b3f3a8-1544-49d7-8d1d-a0b82fc39045'), HumanMessage(content=' me fale sobre o clube de futebol do Brasil Palmeiras', additional_kwargs={}, response_metadata={}, id='faf47227-411e-4efe-be88-d58003235ec0')]\n",
      "[HumanMessage(content=\"Follow the user's instructions:\", additional_kwargs={}, response_metadata={}, id='9896d36a-30fb-4b47-af76-34fcf9685aba'), HumanMessage(content=' Olá, tudo bem?', additional_kwargs={}, response_metadata={}, id='d1e1ccbd-d706-46d3-b394-021a55f0e426'), HumanMessage(content='Olá! Sim, tudo bem! Como posso ajudar você hoje?', additional_kwargs={}, response_metadata={}, id='e33ddf6c-02ea-44ca-81ea-3add4fb0101a'), HumanMessage(content=\"Follow the user's instructions:\", additional_kwargs={}, response_metadata={}, id='01b3f3a8-1544-49d7-8d1d-a0b82fc39045'), HumanMessage(content=' me fale sobre o clube de futebol do Brasil Palmeiras', additional_kwargs={}, response_metadata={}, id='faf47227-411e-4efe-be88-d58003235ec0'), HumanMessage(content='O Palmeiras é um dos clubes de futebol mais tradicionais e bem-sucedidos do Brasil. Fundado em 26 de agosto de 1914, o clube tem sua sede em São Paulo e manda seus jogos no Allianz Parque, um estádio moderno e confortável.\\n\\nO Palmeiras tem uma rica história no futebol brasileiro, com uma grande quantidade de títulos conquistados ao longo dos anos. O clube é conhecido por sua torcida apaixonada e fiel, que o acompanha em todos os lugares.\\n\\n Alguns dos principais títulos do Palmeiras incluem:\\n\\n* 10 títulos do Campeonato Brasileiro (1960, 1967, 1967, 1969, 1972, 1973, 1993, 1994, 2016 e 2018)\\n* 4 títulos da Copa do Brasil (1998, 2012, 2015 e 2020)\\n* 1 título da Copa Libertadores da América (2020)\\n* 1 título da Copa Mercosul (1998)\\n\\nO Palmeiras também é conhecido por ter revelado grandes jogadores ao longo da história, como Ademir da Guia, Djalma Santos e Marcos.\\n\\nO clube tem uma grande rivalidade com outros times de São Paulo, especialmente o Corinthians, com quem disputa o Derby Paulista.\\n\\nHoje em dia, o Palmeiras continua a ser um dos principais clubes do futebol brasileiro, com uma estrutura sólida e um elenco competitivo.', additional_kwargs={}, response_metadata={}, id='e15452b4-b1ba-42a5-a323-029b69d3ad3d')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the transcription:  Meu nome é Jefferson. Você tem um nome?\n",
      "[HumanMessage(content=' Meu nome é Jefferson. Você tem um nome?', additional_kwargs={}, response_metadata={})]\n",
      "Olá Jefferson! É um prazer conhecê-lo. Eu sou um modelo de linguagem, então não tenho um nome pessoal, mas estou aqui para ajudá-lo com qualquer pergunta ou assunto que você queira discutir. Como posso ajudá-lo hoje?\n",
      "Error in text-to-speech: Error code: 500 - {'error': {'message': 'Internal Server Error', 'type': 'internal_server_error'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the transcription:  но все сами мы онове подъеме формат\n",
      "[HumanMessage(content=' но все сами мы онове подъеме формат', additional_kwargs={}, response_metadata={})]\n",
      "Похоже, что у вас есть предложение или фраза на русском языке, но она не полностью сформирована или содержит ошибки. Если вы пытаетесь сказать что-то о формате или обсуждении какого-то вопроса, я готов помочь.\n",
      "\n",
      "Если вы имели в виду обсудить какой-то конкретный формат или тему, пожалуйста, уточните или предоставьте больше контекста, чтобы я мог лучше понять ваш вопрос и дать более точный ответ.\n",
      "Error in text-to-speech: Error code: 500 - {'error': {'message': 'Internal Server Error', 'type': 'internal_server_error'}}\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph_compiled.stream({\"messages\":HumanMessage(content=\"Follow the user's instructions:\")}, stream_mode=\"values\", config=config):\n",
    "    print(chunk[\"messages\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf81914f-0c5e-4708-9511-caaefdae0468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording your instruction! ... Press Enter to stop recording.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the transcription:  Olá, tudo bem?\n",
      "Error in elevenlabs: headers: {'date': 'Fri, 15 Aug 2025 12:51:53 GMT', 'server': 'uvicorn', 'content-length': '171', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'access-control-allow-headers': '*', 'access-control-allow-methods': 'POST, PATCH, OPTIONS, DELETE, GET, PUT', 'access-control-max-age': '600', 'strict-transport-security': 'max-age=31536000; includeSubDomains', 'x-trace-id': '508922020623fac13766cd7ad2f9e9ce', 'x-region': 'us-central1', 'via': '1.1 google, 1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 401, body: {'detail': {'status': 'quota_exceeded', 'message': 'This request exceeds your quota of 10000. You have 12 credits remaining, while 48 credits are required for this request.'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jefer\\AppData\\Local\\Temp\\ipykernel_39764\\4060166178.py:225: WavFileWarning: Reached EOF prematurely; finished at 537681 bytes, expected 4294967303 bytes from header.\n",
      "  sample_rate, audio_data = read(temp_audio_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"Follow the user's instructions:\", additional_kwargs={}, response_metadata={}, id='a34d14c1-6f02-445e-92af-e9480be4d694'),\n",
       "  HumanMessage(content=' Olá, tudo bem?', additional_kwargs={}, response_metadata={}, id='b092714e-e223-4471-9ea8-6c268d0f71f8'),\n",
       "  HumanMessage(content='Olá! Sim, tudo bem! Como posso ajudar você hoje?', additional_kwargs={}, response_metadata={}, id='63cfd078-fca1-4afd-9bf0-67e60eb86285'),\n",
       "  HumanMessage(content=\"Follow the user's instructions:\", additional_kwargs={}, response_metadata={}, id='d14de755-641f-4ccb-be87-9190efe527f1'),\n",
       "  HumanMessage(content=' Olá, tudo bem?', additional_kwargs={}, response_metadata={}, id='3019e04f-decd-46dd-95e0-2cf2be1a1277'),\n",
       "  HumanMessage(content='Olá! Sim, tudo bem! Como posso ajudar você hoje?', additional_kwargs={}, response_metadata={}, id='4941e2dd-8335-4935-9211-8193897c72aa'),\n",
       "  HumanMessage(content=\"Follow the user's instructions:\", additional_kwargs={}, response_metadata={}, id='ff6c499a-b385-48cf-b340-21ea0195a450'),\n",
       "  HumanMessage(content=' Olá, tudo bem?', additional_kwargs={}, response_metadata={}, id='b636e3c8-43bb-47c0-94e6-df32cc3b6a14'),\n",
       "  HumanMessage(content='Olá! Sim, tudo bem! Como posso ajudar você hoje?', additional_kwargs={}, response_metadata={}, id='ea5eb78f-48f8-4da8-905f-1d2417cb3781')]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_compiled.invoke({\"messages\":HumanMessage(content=\"Follow the user's instructions:\")}, config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "677810d1-7221-448b-b2a5-ae40b4bf6d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Follow the user's instructions:\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      " Olá, tudo bem?\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Olá! Sim, tudo bem! Como posso ajudar você hoje?\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Follow the user's instructions:\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      " Olá, tudo bem?\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Olá! Sim, tudo bem! Como posso ajudar você hoje?\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Follow the user's instructions:\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      " Olá, tudo bem?\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Olá! Sim, tudo bem! Como posso ajudar você hoje?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "state = graph_compiled.get_state(config)\n",
    "\n",
    "ChatPromptTemplate.from_messages(state.values[\"messages\"]).pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bbaa38-043a-41fd-9a6c-0a492132b52f",
   "metadata": {},
   "source": [
    "# ElevenLabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a40dada-0732-4da4-9058-a0e1704c1d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elevenlabs.client import ElevenLabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "003fb8c9-5f9e-4ec6-bd6d-171bda231ed3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ApiError",
     "evalue": "headers: {'date': 'Fri, 15 Aug 2025 12:52:00 GMT', 'server': 'uvicorn', 'content-length': '172', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'access-control-allow-headers': '*', 'access-control-allow-methods': 'POST, PATCH, OPTIONS, DELETE, GET, PUT', 'access-control-max-age': '600', 'strict-transport-security': 'max-age=31536000; includeSubDomains', 'x-trace-id': 'e702dc188e45c5960721920da0a6c71d', 'x-region': 'us-central1', 'via': '1.1 google, 1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 401, body: {'detail': {'status': 'quota_exceeded', 'message': 'This request exceeds your quota of 10000. You have 12 credits remaining, while 119 credits are required for this request.'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mApiError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 26\u001b[0m\n\u001b[0;32m     10\u001b[0m elevenlabs \u001b[38;5;241m=\u001b[39m ElevenLabs(\n\u001b[0;32m     11\u001b[0m   api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mELEVENLABS_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     14\u001b[0m audio \u001b[38;5;241m=\u001b[39m elevenlabs\u001b[38;5;241m.\u001b[39mtext_to_speech\u001b[38;5;241m.\u001b[39mconvert(\n\u001b[0;32m     15\u001b[0m     text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDesculpe, mas não tenho informações sobre o seu nome. Você não me forneceu essa informação. Posso ajudar com algo mais?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m     voice_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJBFqnCBsd6RMkjVDRZzb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m     output_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmp3_44100_128\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     24\u001b[0m )\n\u001b[1;32m---> 26\u001b[0m play(audio)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\elevenlabs\\play.py:19\u001b[0m, in \u001b[0;36mplay\u001b[1;34m(audio, notebook, use_ffmpeg)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplay\u001b[39m(\n\u001b[0;32m     14\u001b[0m     audio: Union[\u001b[38;5;28mbytes\u001b[39m, Iterator[\u001b[38;5;28mbytes\u001b[39m]], \n\u001b[0;32m     15\u001b[0m     notebook: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[0;32m     16\u001b[0m     use_ffmpeg: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     17\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(audio, Iterator):\n\u001b[1;32m---> 19\u001b[0m         audio \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(audio)\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m notebook:\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\elevenlabs\\text_to_speech\\client.py:163\u001b[0m, in \u001b[0;36mTextToSpeechClient.convert\u001b[1;34m(self, voice_id, text, enable_logging, optimize_streaming_latency, output_format, model_id, language_code, voice_settings, pronunciation_dictionary_locators, seed, previous_text, next_text, previous_request_ids, next_request_ids, use_pvc_as_ivc, apply_text_normalization, apply_language_text_normalization, request_options)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     54\u001b[0m     voice_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     76\u001b[0m     request_options: typing\u001b[38;5;241m.\u001b[39mOptional[RequestOptions] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     77\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[0;32m     78\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;124;03m    Converts text into speech using a voice of your choice and returns audio.\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;124;03m    )\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_client\u001b[38;5;241m.\u001b[39mconvert(\n\u001b[0;32m    164\u001b[0m         voice_id,\n\u001b[0;32m    165\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m    166\u001b[0m         enable_logging\u001b[38;5;241m=\u001b[39menable_logging,\n\u001b[0;32m    167\u001b[0m         optimize_streaming_latency\u001b[38;5;241m=\u001b[39moptimize_streaming_latency,\n\u001b[0;32m    168\u001b[0m         output_format\u001b[38;5;241m=\u001b[39moutput_format,\n\u001b[0;32m    169\u001b[0m         model_id\u001b[38;5;241m=\u001b[39mmodel_id,\n\u001b[0;32m    170\u001b[0m         language_code\u001b[38;5;241m=\u001b[39mlanguage_code,\n\u001b[0;32m    171\u001b[0m         voice_settings\u001b[38;5;241m=\u001b[39mvoice_settings,\n\u001b[0;32m    172\u001b[0m         pronunciation_dictionary_locators\u001b[38;5;241m=\u001b[39mpronunciation_dictionary_locators,\n\u001b[0;32m    173\u001b[0m         seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[0;32m    174\u001b[0m         previous_text\u001b[38;5;241m=\u001b[39mprevious_text,\n\u001b[0;32m    175\u001b[0m         next_text\u001b[38;5;241m=\u001b[39mnext_text,\n\u001b[0;32m    176\u001b[0m         previous_request_ids\u001b[38;5;241m=\u001b[39mprevious_request_ids,\n\u001b[0;32m    177\u001b[0m         next_request_ids\u001b[38;5;241m=\u001b[39mnext_request_ids,\n\u001b[0;32m    178\u001b[0m         use_pvc_as_ivc\u001b[38;5;241m=\u001b[39muse_pvc_as_ivc,\n\u001b[0;32m    179\u001b[0m         apply_text_normalization\u001b[38;5;241m=\u001b[39mapply_text_normalization,\n\u001b[0;32m    180\u001b[0m         apply_language_text_normalization\u001b[38;5;241m=\u001b[39mapply_language_text_normalization,\n\u001b[0;32m    181\u001b[0m         request_options\u001b[38;5;241m=\u001b[39mrequest_options,\n\u001b[0;32m    182\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m r:\n\u001b[0;32m    183\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m r\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\elevenlabs\\text_to_speech\\raw_client.py:210\u001b[0m, in \u001b[0;36mRawTextToSpeechClient.convert\u001b[1;34m(self, voice_id, text, enable_logging, optimize_streaming_latency, output_format, model_id, language_code, voice_settings, pronunciation_dictionary_locators, seed, previous_text, next_text, previous_request_ids, next_request_ids, use_pvc_as_ivc, apply_text_normalization, apply_language_text_normalization, request_options)\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ApiError(\n\u001b[0;32m    206\u001b[0m             status_code\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mstatus_code, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(_response\u001b[38;5;241m.\u001b[39mheaders), body\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m    207\u001b[0m         )\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ApiError(status_code\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mstatus_code, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(_response\u001b[38;5;241m.\u001b[39mheaders), body\u001b[38;5;241m=\u001b[39m_response_json)\n\u001b[1;32m--> 210\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m _stream()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\elevenlabs\\text_to_speech\\raw_client.py:208\u001b[0m, in \u001b[0;36mRawTextToSpeechClient.convert.<locals>._stream\u001b[1;34m()\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError:\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ApiError(\n\u001b[0;32m    206\u001b[0m         status_code\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mstatus_code, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(_response\u001b[38;5;241m.\u001b[39mheaders), body\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m    207\u001b[0m     )\n\u001b[1;32m--> 208\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ApiError(status_code\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mstatus_code, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(_response\u001b[38;5;241m.\u001b[39mheaders), body\u001b[38;5;241m=\u001b[39m_response_json)\n",
      "\u001b[1;31mApiError\u001b[0m: headers: {'date': 'Fri, 15 Aug 2025 12:52:00 GMT', 'server': 'uvicorn', 'content-length': '172', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'access-control-allow-headers': '*', 'access-control-allow-methods': 'POST, PATCH, OPTIONS, DELETE, GET, PUT', 'access-control-max-age': '600', 'strict-transport-security': 'max-age=31536000; includeSubDomains', 'x-trace-id': 'e702dc188e45c5960721920da0a6c71d', 'x-region': 'us-central1', 'via': '1.1 google, 1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 401, body: {'detail': {'status': 'quota_exceeded', 'message': 'This request exceeds your quota of 10000. You have 12 credits remaining, while 119 credits are required for this request.'}}"
     ]
    }
   ],
   "source": [
    "# choco install ffmpeg\n",
    "# site para vozes https://elevenlabs.io/app/voice-library?search=brazil\n",
    "from dotenv import load_dotenv\n",
    "from elevenlabs.client import ElevenLabs\n",
    "from elevenlabs import play\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "elevenlabs = ElevenLabs(\n",
    "  api_key=os.getenv(\"ELEVENLABS_API_KEY\"),\n",
    ")\n",
    "\n",
    "audio = elevenlabs.text_to_speech.convert(\n",
    "    text=\"Desculpe, mas não tenho informações sobre o seu nome. Você não me forneceu essa informação. Posso ajudar com algo mais?\",\n",
    "    voice_id=\"JBFqnCBsd6RMkjVDRZzb\",\n",
    "    #model_id=\"eleven_multilingual_v2\",\n",
    "    #voice_id=\"GnDrTQvdzZ7wqAKfLzVQ\",\n",
    "    #voice_id = \"8ydzsJeYlXGq5mRMX93B\",\n",
    "    #voice_id=\"EIkHVdkuarjkYUyMnoes\",\n",
    "    \n",
    "    model_id=\"eleven_multilingual_v1\",\n",
    "    output_format=\"mp3_44100_128\",\n",
    ")\n",
    "\n",
    "play(audio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f66207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
